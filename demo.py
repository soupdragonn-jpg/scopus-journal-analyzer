"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–µ–Ω —Å–∫—Ä–∏–ø—Ç –∑–∞ Scopus Journal Analyzer
–ü–æ–∫–∞–∑–≤–∞ –∫–∞–∫ –¥–∞ –∏–∑–ø–æ–ª–∑–≤–∞—Ç–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø—Ä–æ–≥—Ä–∞–º–Ω–æ
"""

import json
from app import ScopusJournalAnalyzer
from scopus_api import ScopusEnhancer

def demo_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ —Å–ø–∏—Å–∞–Ω–∏–µ"""
    
    print("=" * 60)
    print("SCOPUS JOURNAL READINESS ANALYZER - –î–ï–ú–û")
    print("=" * 60)
    
    # –°—ä–∑–¥–∞–≤–∞–º–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = ScopusJournalAnalyzer()
    enhancer = ScopusEnhancer()
    
    # –ü—Ä–∏–º–µ—Ä–Ω–∏ URL –∞–¥—Ä–µ—Å–∏ –∑–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ
    test_urls = [
        "https://www.nature.com/nature/",
        "https://www.science.org/journal/science",
        "https://www.cell.com/cell/",
        "https://www.nejm.org/",
        "https://www.thelancet.com/"
    ]
    
    print("–î–æ—Å—Ç—É–ø–Ω–∏ —Ç–µ—Å—Ç–æ–≤–∏ URL –∞–¥—Ä–µ—Å–∏:")
    for i, url in enumerate(test_urls, 1):
        print(f"{i}. {url}")
    
    # –ü–∏—Ç–∞–º–µ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è –∑–∞ –∏–∑–±–æ—Ä
    try:
        choice = input("\n–ò–∑–±–µ—Ä–µ—Ç–µ –Ω–æ–º–µ—Ä (1-5) –∏–ª–∏ –≤—ä–≤–µ–¥–µ—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω URL: ")
        
        if choice.isdigit() and 1 <= int(choice) <= len(test_urls):
            selected_url = test_urls[int(choice) - 1]
        else:
            selected_url = choice
            if not selected_url.startswith(('http://', 'https://')):
                selected_url = 'https://' + selected_url
        
        print(f"\n–ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º: {selected_url}")
        print("–ú–æ–ª—è –∏–∑—á–∞–∫–∞–π—Ç–µ...")
        
        # –ò–∑–≤—ä—Ä—à–≤–∞–º–µ –∞–Ω–∞–ª–∏–∑–∞
        journal_data = analyzer.extract_journal_data(selected_url)
        
        if 'error' in journal_data:
            print(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑: {journal_data['error']}")
            return
        
        # –ü–æ–¥–æ–±—Ä—è–≤–∞–º–µ –∞–Ω–∞–ª–∏–∑–∞ —Å Scopus –¥–∞–Ω–Ω–∏
        enhanced_data = enhancer.enhance_journal_analysis(journal_data)
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞–º–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—Ç–∞
        readiness_analysis = analyzer.calculate_scopus_readiness(enhanced_data)
        
        # –ü–æ–∫–∞–∑–≤–∞–º–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        display_results(enhanced_data, readiness_analysis)
        
        # –ó–∞–ø–∞–∑–≤–∞–º–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        save_results(enhanced_data, readiness_analysis, selected_url)
        
    except KeyboardInterrupt:
        print("\n–ê–Ω–∞–ª–∏–∑—ä—Ç –µ –ø—Ä–µ–∫—ä—Å–Ω–∞—Ç –æ—Ç –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è")
    except Exception as e:
        print(f"–ì—Ä–µ—à–∫–∞: {e}")

def display_results(journal_data, readiness_analysis):
    """–ü–æ–∫–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –æ—Ç –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("\n" + "=" * 60)
    print("–†–ï–ó–£–õ–¢–ê–¢–ò –û–¢ –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 60)
    
    # –û—Å–Ω–æ–≤–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print(f"\nüì∞ –ó–ê–ì–õ–ê–í–ò–ï: {journal_data.get('title', '–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ')}")
    print(f"üîó URL: {journal_data.get('url', '–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ')}")
    print(f"üìÑ ISSN: {journal_data.get('issn', '–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ')}")
    print(f"üî¢ DOI Prefix: {journal_data.get('doi_prefix', '–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ')}")
    print(f"üåê Open Access: {'–î–∞' if journal_data.get('open_access') else '–ù–µ'}")
    print(f"üó£Ô∏è –ï–∑–∏—Ü–∏: {', '.join(journal_data.get('languages', ['–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ']))}")
    print(f"üìÖ –ß–µ—Å—Ç–æ—Ç–∞: {journal_data.get('publication_frequency', '–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ')}")
    print(f"üë• –†–µ–¥–∞–∫—Ü–∏–æ–Ω–µ–Ω —Å—ä–≤–µ—Ç: {len(journal_data.get('editorial_board', []))} —á–ª–µ–Ω–æ–≤–µ")
    
    # –û–±—â–∞ –æ—Ü–µ–Ω–∫–∞
    total_score = readiness_analysis['total_score']
    readiness_level = readiness_analysis['readiness_level']
    
    print(f"\nüéØ –û–ë–©–ê –û–¶–ï–ù–ö–ê: {total_score:.1f}%")
    print(f"üìä –ù–ò–í–û –ù–ê –ì–û–¢–û–í–ù–û–°–¢: {readiness_level}")
    
    # –¶–≤–µ—Ç–æ–≤–æ –∫–æ–¥–∏—Ä–∞–Ω–µ
    if total_score >= 80:
        emoji = "üü¢"
        status = "–û–¢–õ–ò–ß–ù–û"
    elif total_score >= 60:
        emoji = "üü°"
        status = "–î–û–ë–†–ï"
    elif total_score >= 40:
        emoji = "üü†"
        status = "–°–†–ï–î–ù–û"
    else:
        emoji = "üî¥"
        status = "–°–õ–ê–ë–û"
    
    print(f"{emoji} –°–¢–ê–¢–£–°: {status}")
    
    # –î–µ—Ç–∞–π–ª–Ω–∏ –æ—Ü–µ–Ω–∫–∏
    print(f"\nüìà –î–ï–¢–ê–ô–õ–ù–ò –û–¶–ï–ù–ö–ò:")
    detailed_scores = readiness_analysis['detailed_scores']
    
    criteria_names = {
        'content_quality': '–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ—Ç–æ',
        'editorial_standards': '–†–µ–¥–∞–∫—Ü–∏–æ–Ω–Ω–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏',
        'peer_review_process': 'Peer Review –ø—Ä–æ—Ü–µ—Å',
        'international_scope': '–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–µ–Ω –æ–±—Ö–≤–∞—Ç',
        'technical_standards': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏',
        'accessibility': '–î–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç'
    }
    
    for key, score in detailed_scores.items():
        name = criteria_names.get(key, key)
        bar = "‚ñà" * int(score / 5) + "‚ñë" * (20 - int(score / 5))
        print(f"  {name}: {score:5.1f}% {bar}")
    
    # Scopus —Å—Ç–∞—Ç—É—Å
    scopus_status = journal_data.get('scopus_indexing_status', {})
    if scopus_status.get('indexed'):
        print(f"\n‚úÖ SCOPUS –°–¢–ê–¢–£–°: –í–µ—á–µ –µ –∏–Ω–¥–µ–∫—Å–∏—Ä–∞–Ω–æ")
        scopus_data = scopus_status.get('scopus_data', {})
        if scopus_data.get('scopus_id'):
            print(f"üÜî Scopus ID: {scopus_data['scopus_id']}")
        if scopus_data.get('subject_areas'):
            print(f"üìö –ü—Ä–µ–¥–º–µ—Ç–Ω–∏ –æ–±–ª–∞—Å—Ç–∏: {', '.join(scopus_data['subject_areas'])}")
    else:
        print(f"\n‚ùå SCOPUS –°–¢–ê–¢–£–°: –ù–µ –µ –∏–Ω–¥–µ–∫—Å–∏—Ä–∞–Ω–æ")
        print(f"üí° –ü—Ä–µ–ø–æ—Ä—ä–∫–∞: {scopus_status.get('recommendation', '–ú–æ–∂–µ –¥–∞ —Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∏—Ä–∞')}")
    
    # –ü—Ä–µ–ø–æ—Ä—ä–∫–∏
    recommendations = readiness_analysis.get('recommendations', [])
    if recommendations:
        print(f"\nüí° –ü–†–ï–ü–û–†–™–ö–ò –ó–ê –ü–û–î–û–ë–†–ï–ù–ò–ï:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")
    else:
        print(f"\nüéâ –ü–†–ï–ü–û–†–™–ö–ò: –°–ø–∏—Å–∞–Ω–∏–µ—Ç–æ –æ—Ç–≥–æ–≤–∞—Ä—è –Ω–∞ –≤—Å–∏—á–∫–∏ –æ—Å–Ω–æ–≤–Ω–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏!")

def save_results(journal_data, readiness_analysis, url):
    """–ó–∞–ø–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –≤—ä–≤ —Ñ–∞–π–ª"""
    
    results = {
        'url': url,
        'analysis_date': journal_data.get('analysis_timestamp'),
        'journal_data': journal_data,
        'readiness_analysis': readiness_analysis
    }
    
    filename = f"analysis_results_{url.replace('https://', '').replace('http://', '').replace('/', '_')}.json"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ –†–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ —Å–∞ –∑–∞–ø–∞–∑–µ–Ω–∏ –≤: {filename}")
    except Exception as e:
        print(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∞–∑–≤–∞–Ω–µ: {e}")

def demo_batch_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –≥—Ä—É–ø–æ–≤ –∞–Ω–∞–ª–∏–∑"""
    
    print("\n" + "=" * 60)
    print("–ì–†–£–ü–û–í –ê–ù–ê–õ–ò–ó –ù–ê –°–ü–ò–°–ê–ù–ò–Ø")
    print("=" * 60)
    
    # –°–ø–∏—Å—ä–∫ —Å URL –∞–¥—Ä–µ—Å–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑
    urls = [
        "https://www.nature.com/nature/",
        "https://www.science.org/journal/science",
        "https://www.cell.com/cell/"
    ]
    
    analyzer = ScopusJournalAnalyzer()
    results = []
    
    for i, url in enumerate(urls, 1):
        print(f"\n–ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º {i}/{len(urls)}: {url}")
        
        try:
            journal_data = analyzer.extract_journal_data(url)
            if 'error' not in journal_data:
                readiness_analysis = analyzer.calculate_scopus_readiness(journal_data)
                results.append({
                    'url': url,
                    'title': journal_data.get('title', '–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ'),
                    'score': readiness_analysis['total_score'],
                    'level': readiness_analysis['readiness_level']
                })
                print(f"‚úì –ó–∞–≤—ä—Ä—à–µ–Ω - –û—Ü–µ–Ω–∫–∞: {readiness_analysis['total_score']:.1f}%")
            else:
                print(f"‚úó –ì—Ä–µ—à–∫–∞: {journal_data['error']}")
        except Exception as e:
            print(f"‚úó –ì—Ä–µ—à–∫–∞: {e}")
    
    # –ü–æ–∫–∞–∑–≤–∞–º–µ –æ–±–æ–±—â–µ–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
    if results:
        print(f"\nüìä –û–ë–û–ë–©–ï–ù–ò –†–ï–ó–£–õ–¢–ê–¢–ò:")
        print("-" * 60)
        results.sort(key=lambda x: x['score'], reverse=True)
        
        for i, result in enumerate(results, 1):
            print(f"{i}. {result['title'][:50]}...")
            print(f"   URL: {result['url']}")
            print(f"   –û—Ü–µ–Ω–∫–∞: {result['score']:.1f}% ({result['level']})")
            print()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("–ò–∑–±–µ—Ä–µ—Ç–µ —Ä–µ–∂–∏–º:")
    print("1. –ê–Ω–∞–ª–∏–∑ –Ω–∞ –µ–¥–Ω–æ —Å–ø–∏—Å–∞–Ω–∏–µ")
    print("2. –ì—Ä—É–ø–æ–≤ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –Ω—è–∫–æ–ª–∫–æ —Å–ø–∏—Å–∞–Ω–∏—è")
    print("3. –ò–∑—Ö–æ–¥")
    
    choice = input("\n–í–∞—à–∏—è—Ç –∏–∑–±–æ—Ä (1-3): ")
    
    if choice == '1':
        demo_analysis()
    elif choice == '2':
        demo_batch_analysis()
    elif choice == '3':
        print("–î–æ–≤–∏–∂–¥–∞–Ω–µ!")
    else:
        print("–ù–µ–≤–∞–ª–∏–¥–µ–Ω –∏–∑–±–æ—Ä!")

if __name__ == '__main__':
    main()
